{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordinate descent\n",
    "\n",
    "Coordinate descent is a widely used optimization method.\n",
    "\n",
    "We let $f: \\mathbb{R}^p \\to \\mathbb{R}$. Coordinate descent tries to minimize $f$ alternatively with respect to individual coordinates.\n",
    "\n",
    "We denote $w^t$ the iterates. At iteration $t$, we chose an index $i \\in \\{1, \\dots, p\\}$ and try to minimize $f$ with respect to $w_i^t$ without changing the other coordinates $w_j^t$, $j\\neq i$. More formally, we define $\\phi_i(x, w) = f(w_1, \\dots, w_{i-1}, x, w_{i+1}, w_p)$ and set (ideally) at each iteration: \n",
    "\n",
    "$$\n",
    "w_i^{t+1} = \\arg\\min_x \\phi_i(x, w^t) \\enspace \\text{and} \\enspace w_j^{t+1} = w_j^t \\enspace \\text{for} \\enspace j\\neq i\n",
    "$$\n",
    "\n",
    "The index $i$ is typically chosen as cyclic : $i =1 + (t \\mod p)$. Therefore , at iteration $1$, the coordinate $1$ is updated, at iteration $2$, the coordinate $2$ is updated, ... , at iteration $p$ the coordinate $p$ is updated, and at iteration $p+1$ the coordinate $1$ is modified again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we will study the behavior of the method for quadratic functions: we assume that $f(w) = \\frac12 w^{\\top}Aw - b^{\\top}w$ with $A\\in \\mathbb{R}^{p\\times p}$ a positive symmetric matrix and $b \\in \\mathbb{R}^p$ a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1**: Write down explicitely one coordinate descent step that corresponds to index $i$ on $f$. Can you recast it as a gradient descent step on $\\phi_i$? With which step-size? Compare to the classical step-size for gradient descent on $f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 10\n",
    "A = np.random.randn(p, p)\n",
    "A = np.dot(A, A.T)\n",
    "b = np.random.randn(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w):\n",
    "    return 0.5 * np.dot(w, np.dot(A, w)) - np.dot(b, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question 2**: implement the coordinate descent method by completing the following function. Also complete the gradient descent function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinate_descent(A, b, n_iters):\n",
    "    _, p = A.shape\n",
    "    w = np.zeros(p)\n",
    "    w_list = []\n",
    "    for t in range(n_iters):\n",
    "        w_list.append(w.copy())\n",
    "        i = t % p\n",
    "        # your code here\n",
    "    return np.array(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(A, b, n_iters, step):\n",
    "    _, p = A.shape\n",
    "    w = np.zeros(p)\n",
    "    w_list = []\n",
    "    for t in range(n_iters):\n",
    "        w_list.append(w.copy())\n",
    "        # your code here\n",
    "    return np.array(w_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**: Display the convergence curves for this algorithm. Compare them with gradient descent with the usual step size $\\frac1{\\sigma_{\\max}(A)}$. Which method is faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** We can add a step-size $\\gamma$ in the coordinate descent method. The updated coordinate becomes:\n",
    "$$w_i^{t+1} = w_i^t - \\gamma \\frac{1}{A_{ii}}(\\sum_{j}A_{ij}w_j^t - b_i).$$\n",
    "Test the influence of the step-size on convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
